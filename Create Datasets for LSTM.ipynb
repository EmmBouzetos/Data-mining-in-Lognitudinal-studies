{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7dc38a0-220c-4688-8abe-c648d996c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d3fb58-fc89-4dab-906f-edc73d77345d",
   "metadata": {},
   "source": [
    "Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e96f79e-572b-4499-af30-25a918e3e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv (r'C:\\Users\\Manos\\OneDrive\\My_thesis\\tab_per_wave\\Wave_2\\wave_2_nurse_data_v2.tab',sep='\\t',low_memory=False)\n",
    "df2 = pd.read_csv (r'C:\\Users\\Manos\\OneDrive\\My_thesis\\tab_per_wave\\Wave_4\\wave_4_nurse_data.tab',sep='\\t',low_memory=False)\n",
    "df3 = pd.read_csv (r'C:\\Users\\Manos\\OneDrive\\My_thesis\\tab_per_wave\\Wave_6\\wave_6_elsa_nurse_data_v2.tab',sep='\\t',low_memory=False)\n",
    "df4 = pd.read_csv (r'C:\\Users\\Manos\\OneDrive\\My_thesis\\tab_per_wave\\Wave_9\\elsa_nurse_w8w9_data_eul.tab',sep='\\t',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65e883-b524-4263-873c-e7ae8d133c1c",
   "metadata": {},
   "source": [
    "Create Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770bb199-b09f-4e09-80eb-90783f9649f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicto={1:df1,\n",
    "      2:df2,\n",
    "      3:df3,\n",
    "      4:df4\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9185ce-4a59-4ceb-ad73-be1b2a458073",
   "metadata": {},
   "source": [
    "Select Features (The Common nurse examinations across the 4 datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd66f66-85a6-4808-920e-ae132ef46840",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list=['idauniq','sys1','sys2','sys3', 'dias1','dias2', 'dias3','pulse1','pulse2','pulse3','cfib','chol','hdl','trig','ldl',\n",
    "           'rtin','hscrp','hgb','hba1c','mmgsd1','mmgsd2','mmgsd3','mmgsn1','mmgsn2','mmgsn3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fd40c8f-725f-49a6-9174-f728020a455f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7666, 25)\n",
      "(8643, 25)\n",
      "(8054, 25)\n",
      "(6597, 25)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    dicto[i]=dicto[i][feat_list]\n",
    "    print(dicto[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ad7ef-ed3f-478e-9a17-3763f9775e87",
   "metadata": {},
   "source": [
    "Some columns in df4 are type=object we have to convert them to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef5b2a1-535e-40fa-8e36-db06d273dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=dicto[4].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e2c41e-3008-4ee7-989d-2f1ee254a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the indexes of values equal to object and then convert them to a list with .tolist() function\n",
    "list_obj=result[result=='object'].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1419e9ab-42cf-4b4e-8679-7e2fb20fa9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manos\\AppData\\Local\\Temp/ipykernel_15280/1926784061.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dicto[4][list_obj[i]]=pd.to_numeric(dicto[4][list_obj[i]], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,len(list_obj)):\n",
    "    dicto[4][list_obj[i]]=pd.to_numeric(dicto[4][list_obj[i]], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66c128e-ebbd-482e-89be-0e485300818f",
   "metadata": {},
   "source": [
    "replace missing values(>0) with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90820f96-e419-484a-8cc7-a43a79232c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,5):\n",
    "    for x in range(-12,0):\n",
    "     dicto[i]=dicto[i].replace(x,np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455eecf-12f6-4034-9319-b025c0054d05",
   "metadata": {},
   "source": [
    "Missing Value Perchentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "139a4c6e-05c2-4f09-a4bb-65f901c04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         percent_missing\n",
      "idauniq         0.000000\n",
      "sys1            0.257693\n",
      "sys2            0.257693\n",
      "sys3            0.257693\n",
      "dias1           0.257693\n",
      "dias2           0.257693\n",
      "dias3           0.257693\n",
      "pulse1          0.257693\n",
      "pulse2          0.257693\n",
      "pulse3          0.257693\n",
      "cfib           29.574049\n",
      "chol           23.738063\n",
      "hdl            23.738063\n",
      "trig           23.722904\n",
      "ldl            24.602092\n",
      "rtin           23.768380\n",
      "hscrp          23.707746\n",
      "hgb            24.799151\n",
      "hba1c          25.162953\n",
      "mmgsd1          3.350008\n",
      "mmgsd2          3.350008\n",
      "mmgsd3          3.350008\n",
      "mmgsn1          3.456116\n",
      "mmgsn2          3.471275\n",
      "mmgsn3          3.516750\n"
     ]
    }
   ],
   "source": [
    "percent_missing = dicto[4].isnull().sum() * 100 / len(dicto[4])\n",
    "missing_value_df = pd.DataFrame({'percent_missing': percent_missing})\n",
    "print(missing_value_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40e1c2-7eb9-47a3-9b27-5956f1816318",
   "metadata": {},
   "source": [
    "Apply KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80eab83c-859f-45ae-a706-e5ee0e4fc552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define knn\n",
    "from sklearn.impute import KNNImputer\n",
    "knnimputer= KNNImputer(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acb1c450-37bd-45f6-9f47-0504ab8ad32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply knn\n",
    "for i in range (1,5):\n",
    "    dicto[i]=knnimputer.fit_transform(dicto[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fb845ec-b718-4f3d-bd2c-7ccc248bbae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert arrays to pd.frame\n",
    "for i in range (1,5):\n",
    "    dicto[i] = pd.DataFrame(dicto[i], columns = feat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9148b39-b8df-49e8-a3ca-24ac0811f1d3",
   "metadata": {},
   "source": [
    "MinMaXScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839079e9-ecdc-4d90-bd00-5eee3d33dd9b",
   "metadata": {},
   "source": [
    "I will concat all the frames on one frame so i can fit the scaler for all the variations of the datapoint. after that I will transform each dataframe seperatley with the fitted scaler. Important Note i have to save the scaler to invert the results of the LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e45ac045-51b8-4703-91c3-7d1e81773263",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[dicto[1],dicto[2],dicto[3],dicto[4]]\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f2e44b-a1a9-4335-a113-f3b4f1b923d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8379500-7378-423b-ad9e-2bc81ff139df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfca262d-93a0-4b89-8b8b-a78b75e187e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dont use it on idauniq\n",
    "scaler.fit(df.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5eba430-c266-4048-a5de-a176f3256679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save scaler\n",
    "from pickle import dump\n",
    "dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ce18dc6-3d44-4157-9df7-e92331219509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load scaler back\n",
    "# from pickle import load\n",
    "# scaler = load(open('scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df5fb00d-e0ab-4ca4-bb43-95d2ab1525ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df1=scaler.transform(dicto[1].iloc[:,1:])\n",
    "scaled_df2=scaler.transform(dicto[2].iloc[:,1:])\n",
    "scaled_df3=scaler.transform(dicto[3].iloc[:,1:])\n",
    "scaled_df4=scaler.transform(dicto[4].iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0188ef53-59a0-4f56-b895-97571ece2567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #reverse transform problem with underfitting\n",
    "# scaled_df1=scaler.inverse_transform(scaled_df1)\n",
    "# scaled_df2=scaler.inverse_transform(scaled_df2)\n",
    "# scaled_df3=scaler.inverse_transform(scaled_df3)\n",
    "# scaled_df4=scaler.inverse_transform(scaled_df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "361152ae-764f-43d5-8fd0-3836cbd59f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10084926, 0.08858058, 0.09872611, ..., 0.42857143, 0.31313131,\n",
       "        0.3030303 ],\n",
       "       [0.09129512, 0.08431163, 0.09235669, ..., 0.47142857, 0.38383838,\n",
       "        0.35353535],\n",
       "       [0.09872611, 0.0864461 , 0.08704883, ..., 0.42857143, 0.31313131,\n",
       "        0.3030303 ],\n",
       "       ...,\n",
       "       [0.08067941, 0.08217716, 0.08174098, ..., 0.32857143, 0.25252525,\n",
       "        0.27272727],\n",
       "       [0.05307856, 0.06189968, 0.05626327, ..., 0.2       , 0.12121212,\n",
       "        0.1010101 ],\n",
       "       [0.05414013, 0.04482391, 0.04883227, ..., 0.6       , 0.37373737,\n",
       "        0.34343434]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33afc489-087f-491a-bdd9-8cd1fd5e34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe here add padding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48a77bde-baa9-4454-b545-06da83d7b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndicto={1:scaled_df1,\n",
    "      2:scaled_df2,\n",
    "      3:scaled_df3,\n",
    "      4:scaled_df4\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7da8cbb-c63b-49a6-8f88-e6b7079fea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert arrays to pd.frame\n",
    "for i in range (1,5):\n",
    "    ndicto[i] = pd.DataFrame(ndicto[i], columns = feat_list[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ef218-c7a2-494a-b129-33a6dfe45362",
   "metadata": {},
   "source": [
    "Add idauniq col again to find common ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6eeacf64-2c05-4786-8291-909f0cb99146",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,5):\n",
    "    ndicto[i] = pd.concat([dicto[i].iloc[:,0], ndicto[i]], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c766ae7-f2b5-4b07-a44e-2a8e768c2590",
   "metadata": {},
   "source": [
    "Find common ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f352a26-72dc-406d-8153-e39517b4ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[ndicto[1],ndicto[2],ndicto[3],ndicto[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be4c99ed-904c-4079-adfa-41c73ac1d05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manos\\AppData\\Local\\Temp/ipykernel_15280/439335020.py:2: FutureWarning: Passing 'suffixes' which cause duplicate columns {'hba1c_x', 'mmgsn3_x', 'dias3_x', 'rtin_x', 'cfib_x', 'sys1_x', 'hscrp_x', 'mmgsd3_x', 'pulse2_x', 'mmgsn1_x', 'sys2_x', 'mmgsn2_x', 'pulse3_x', 'sys3_x', 'ldl_x', 'hdl_x', 'dias2_x', 'trig_x', 'pulse1_x', 'hgb_x', 'chol_x', 'mmgsd1_x', 'dias1_x', 'mmgsd2_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merged = reduce(lambda  left,right: pd.merge(left,right, on=['idauniq'],\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right, on=['idauniq'],\n",
    "                                            how='inner'), frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af9aaf61-1e2f-411d-993b-6f00c3302508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manos\\AppData\\Local\\Temp/ipykernel_15280/4239322206.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_merged.drop(df_merged.columns.difference(['idauniq',]), 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Make a seiries with the common ids\n",
    "df_merged.drop(df_merged.columns.difference(['idauniq',]), 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c715a8d-d69f-4fd3-a934-6d364dc4e985",
   "metadata": {},
   "source": [
    "drop the ids that are not common from each dataset and export them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a93432f4-6917-45fd-8b07-385f11f52987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropexport(df,location):\n",
    "    df_new=pd.merge(df_merged,df, on=['idauniq'],how='inner')\n",
    "    #print(df_new.head())\n",
    "    df_new = df_new.sort_values(by = 'idauniq') # sort rows by idauniq\n",
    "    df_new.to_csv(location,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53cc9d8c-6348-4873-bac0-8857d44152e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropexport(ndicto[1],r'C:\\Users\\Manos\\OneDrive/Thesis Final/LSTM/Scaled_and_unidemensiolized_datasets\\wave2.tab')\n",
    "dropexport(ndicto[2],r'C:\\Users\\Manos\\OneDrive/Thesis Final/LSTM/Scaled_and_unidemensiolized_datasets\\wave4.tab')\n",
    "dropexport(ndicto[3],r'C:\\Users\\Manos\\OneDrive/Thesis Final/LSTM/Scaled_and_unidemensiolized_datasets\\wave6.tab')\n",
    "dropexport(ndicto[4],r'C:\\Users\\Manos\\OneDrive/Thesis Final/LSTM/Scaled_and_unidemensiolized_datasets\\wave8.tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b307d4a5-c9e3-46f5-91d7-885833c2770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv (r'C:\\Users\\Manos\\OneDrive/Thesis Final/LSTM/Scaled_and_unidemensiolized_datasets\\wave2.tab',sep='\\t',low_memory=False)\n",
    "df2 = pd.read_csv (r'C:\\Users\\Manos\\OneDrive/Thesis Final/LSTM/Scaled_and_unidemensiolized_datasets\\wave4.tab',sep='\\t',low_memory=False)\n",
    "df3 = pd.read_csv (r'C:\\Users\\Manos\\OneDrive/Thesis Final/LSTM/Scaled_and_unidemensiolized_datasets\\wave6.tab',sep='\\t',low_memory=False)\n",
    "df4 = pd.read_csv (r'C:\\Users\\Manos\\OneDrive/Thesis Final/LSTM/Scaled_and_unidemensiolized_datasets\\wave8.tab',sep='\\t',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9190ea8-523e-4709-81f5-e9b5680f2b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2820, 25)\n",
      "(2820, 25)\n",
      "(2820, 25)\n",
      "(2820, 25)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "print(df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "405bca88-7e1d-4794-ad37-cf155f40e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:21:14\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
